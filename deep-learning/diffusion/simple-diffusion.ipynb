{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e09a687-7eb8-4fd7-b416-03aafc7210d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Myo Win Zaw\\.conda\\envs\\ai_env\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613883bc-96bf-4fa2-b02f-1ba789f03017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "\n",
    "dataset_path = '~/datasets'\n",
    "\n",
    "cuda = True\n",
    "DEVICE = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "dataset = 'MNIST'\n",
    "img_size = (32, 32, 3)   if dataset == \"CIFAR10\" else (28, 28, 1) # (width, height, channels)\n",
    "\n",
    "timestep_embedding_dim = 256\n",
    "n_layers = 8\n",
    "hidden_dim = 256\n",
    "n_timesteps = 1000\n",
    "beta_minmax=[1e-4, 2e-2]\n",
    "\n",
    "train_batch_size = 128\n",
    "inference_batch_size = 64\n",
    "lr = 5e-5\n",
    "epochs = 200\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "hidden_dims = [hidden_dim for _ in range(n_layers)]\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20fb89f-d277-4499-96ad-851834c8cf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Users\\Myo Win Zaw/datasets\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñç                                                                 | 1081344/170498071 [00:05<15:35, 181126.92it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_dataset = CIFAR10(dataset_path, transform=transform, train=True, download=True)\n",
    "test_dataset  = CIFAR10(dataset_path, transform=transform, train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "test_loader  = DataLoader(dataset=test_dataset,  batch_size=inference_batch_size, shuffle=False,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72956447-8288-4833-b9d9-30f1f373d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self,dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea51a1a2-6420-44f0-b4ea-61993341133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Conv2d):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a364420-c4a6-4d0d-b713-d91299b8437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Denoiser,self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f1636b-ab35-4fa8-a227-b73a09523a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Diffusion,self).__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c939777-b6e6-4132-821f-1aa1766ba377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
